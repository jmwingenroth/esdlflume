---
title: "LISST exponential model"
output: html_document
---

Note: The 'raw data cleanup' code was partially copypasted from Justin's original data cleaning script, LISST_processing.R

```{r libs}
library(tidyverse)
library(RcppRoll)
library(broom)
```

##Raw data cleanup
```{r}
require(tidyverse)

#Data Quality Control:
#Laser reference >>0
#Transmission should be between 0 and 1 (low transmission indicates turbid water, high tranmission indicates clear water; should disregard these data)

file <- "../data/raw/Flume -- LISST -- Sept 2018-/Flume - size dist data -- 09-12-18.asc"
correction <- TRUE #set this to TRUE if you want to remove all data points that have a transmission outside of the optimal range of 0.1 to 0.995
time_interval <- 1

raw <- read.table(file, header=FALSE) #reading the .asc file as a table

laser_reference <- any(raw[,36]==0) #laser reference values should all be much greater than 0

if (laser_reference==TRUE) {
  warning("Laser reference has a 0 value")
}

transmission <- any(c(raw[,41]<=0, raw[,41]>=1)) #it is physically impossible to have a transmission not in the range 0 to 1

if (transmission==TRUE) {
  warning("Transmission has value(s) outside of the range 0 to 1")
}

if (correction==TRUE) {
  raw <- raw %>%
    filter(V36>0, V41>=0.1, V41<=0.995)
}

time_converted_sec <- raw %>%
  mutate(min=as.numeric(ifelse(V40>=100, gsub("[[:digit:]]{2}$", "", V40), 0))) %>%
  mutate(sec=as.numeric(ifelse(V40>=1000, gsub("^[[:digit:]]{2}", "", V40), ifelse(V40<1000 & V40>=100, gsub("^[[:digit:]]", "", V40), V40)))) %>%
  mutate(sec=sec+(min*60)) %>%
  select(-min) #conversion of time units to seconds

diff <- c(0, diff(time_converted_sec[,"sec"]))
diff[diff<0] <- diff[diff<0]+3600
seconds <- cumsum(diff)+1

time_converted_final <- time_converted_sec %>%
  mutate(sec=seconds) #setting seconds to start at 0 and count increasing (as opposed to cyclically)

gathered_measurements <- time_converted_final %>%
  mutate(group=as.character(ifelse(sec==0, 1, ceiling(sec/(60*time_interval))))) %>%
  gather(key=bin, value=measurement, 1:32) #combining particle concentration data into a single field
```

##Optional tidying
```{r}
#put bins in correct order and group by bin
model_data <- gathered_measurements %>%
  select(sec, bin, measurement) %>%
  mutate(bin = as.integer(str_sub(bin, 2))) %>%
  arrange(bin) %>%
  group_by(bin)

#calculate rolling mean
model_data <- model_data %>%
  mutate(rollmean_1000 = roll_mean(measurement, 1000, fill = NA))

#filter to just exponential decay data
model_data <- model_data %>%
  filter(sec>500)
```

##Rolling mean plots
```{r}
model_data %>%
  ggplot(aes(sec,bin,fill=rollmean_1000)) +
  geom_tile() +
  scale_fill_distiller(palette = "Spectral")

model_data %>%
  ggplot(aes(sec,rollmean_1000,color = as.factor(bin))) +
  geom_line()
```

##Exponential models
```{r}
decay_models <- model_data %>%
  filter(measurement > 0) %>% #cleanup for log regression
  do(model = lm(log(measurement) ~ sec, data = .))

decay_coef <- decay_models %>%
  tidy(model) %>%
  select(bin, term, estimate) %>%
  spread(term, estimate) %>%
  rename(int = '(Intercept)')

model_data %>%
  mutate(pred = exp(decay_coef$int[bin]+sec*decay_coef$sec[bin])) %>%
  gather(type, value, -bin, -sec) %>%
  filter(type!="rollmean_1000") %>%
  ggplot(aes(sec, value, color = type)) +
  geom_line() +
  facet_wrap(~bin, scales = 'free')

decay_models %>%
  glance(model)

decay_coef %>%
  rename(k_total = sec)
  
```

```{r}

model_data %>%
  ungroup() %>%
  group_by(sec) %>%
  summarise(sum = sum(measurement)) %>%
  filter(sum < 45) -> unweighted_sum

unweighted_sum %>%
  lm(log(sum) ~ sec, data = .) -> uws_model

glance(uws_model)

unweighted_sum %>%
  mutate(pred = exp(tidy(uws_model)$estimate[1]+sec*tidy(uws_model)$estimate[2])) %>%
  ggplot(aes(sec)) +
  geom_point(aes(y = sum), alpha = .1) +
  geom_line(aes(y = pred), col = "red")

```

