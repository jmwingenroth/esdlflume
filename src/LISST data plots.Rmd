---
title: "LISST exponential model"
output: html_document
---

Note: The 'raw data cleanup' code was partially copypasted from Justin's original data cleaning script, LISST_processing.R

```{r libs}
library(tidyverse)
library(RcppRoll)
library(broom)
```

##Raw data cleanup
```{r}
require(tidyverse)

#Data Quality Control:
#Laser reference >>0
#Transmission should be between 0 and 1 (low transmission indicates turbid water, high tranmission indicates clear water; should disregard these data)

file <- "../data/raw/Flume -- LISST -- Sept 2018-/Flume - size dist data -- 09-12-18.asc"
correction <- TRUE #set this to TRUE if you want to remove all data points that have a transmission outside of the optimal range of 0.1 to 0.995
time_interval <- 1

raw <- read.table(file, header=FALSE) #reading the .asc file as a table

laser_reference <- any(raw[,36]==0) #laser reference values should all be much greater than 0

if (laser_reference==TRUE) {
  warning("Laser reference has a 0 value")
}

transmission <- any(c(raw[,41]<=0, raw[,41]>=1)) #it is physically impossible to have a transmission not in the range 0 to 1

if (transmission==TRUE) {
  warning("Transmission has value(s) outside of the range 0 to 1")
}

if (correction==TRUE) {
  raw <- raw %>%
    filter(V36>0, V41>=0.1, V41<=0.995)
}

time_converted_sec <- raw %>%
  mutate(min=as.numeric(ifelse(V40>=100, gsub("[[:digit:]]{2}$", "", V40), 0))) %>%
  mutate(sec=as.numeric(ifelse(V40>=1000, gsub("^[[:digit:]]{2}", "", V40), ifelse(V40<1000 & V40>=100, gsub("^[[:digit:]]", "", V40), V40)))) %>%
  mutate(sec=sec+(min*60)) %>%
  select(-min) #conversion of time units to seconds

diff <- c(0, diff(time_converted_sec[,"sec"]))
diff[diff<0] <- diff[diff<0]+3600
seconds <- cumsum(diff)+1

time_converted_final <- time_converted_sec %>%
  mutate(sec=seconds) #setting seconds to start at 0 and count increasing (as opposed to cyclically)

gathered_measurements <- time_converted_final %>%
  mutate(group=as.character(ifelse(sec==0, 1, ceiling(sec/(60*time_interval))))) %>%
  gather(key=bin, value=measurement, 1:32) #combining particle concentration data into a single field
```

##Tidying into model data
```{r}
#put bins in correct order and group by bin
model_data <- gathered_measurements %>%
  select(sec, bin, measurement) %>%
  mutate(bin = as.integer(str_sub(bin, 2))) %>%
  arrange(bin) %>%
  group_by(bin)

#calculate rolling mean
model_data <- model_data %>%
  mutate(rollmean_1000 = roll_mean(measurement, 1000, fill = NA))

#filter out data from before sediment was added
model_data <- model_data %>%
  filter(sec>500)

#getting rid of raw and semi-processed data
rm(list = c("gathered_measurements",
          "raw",
          "time_converted_final",
          "time_converted_sec",
          "correction",
          "diff",
          "laser_reference",
          "seconds",
          "time_interval",
          "transmission"))

```

##Rolling mean plots
```{r}
model_data %>%
  ggplot(aes(sec,bin,fill=rollmean_1000)) +
  geom_tile() +
  scale_fill_distiller(palette = "Spectral")

model_data %>%
  ggplot(aes(sec,rollmean_1000,color = as.factor(bin))) +
  geom_line()
```

##Simple exponential models from unedited data
```{r}
decay_models <- model_data %>%
  filter(measurement > 0) %>% #cleanup for log regression
  do(model = lm(log(measurement) ~ sec, data = .))

decay_coef <- decay_models %>%
  tidy(model) %>%
  select(bin, term, estimate) %>%
  spread(term, estimate) %>%
  rename(int = '(Intercept)')

model_data %>%
  mutate(pred = exp(decay_coef$int[bin]+sec*decay_coef$sec[bin])) %>%
  gather(type, value, -bin, -sec) %>%
  filter(type!="rollmean_1000") %>%
  ggplot(aes(sec, value, color = type)) +
  geom_line() +
  facet_wrap(~bin, scales = 'free')

decay_models %>%
  glance(model)

decay_coef %>%
  rename(k_total = sec)
```

```{r}
model_data %>%
  ungroup() %>%
  group_by(sec) %>%
  summarise(sum = sum(measurement)) -> total_vol

total_vol %>%
  lm(log(sum) ~ sec, data = .) -> sum_model

glance(sum_model)

total_vol %>%
  mutate(pred = exp(tidy(sum_model)$estimate[1]+sec*tidy(sum_model)$estimate[2])) %>%
  ggplot(aes(sec)) +
  geom_point(aes(y = sum), alpha = .1) +
  geom_line(aes(y = pred), col = "red")
```

##Exponential models for data excluding beginning fluctuations and outliers
```{r}

increment <- 50
start <- 1000
n <- 20

all_models <- total_vol %>% #get rid of clumps of outliers in upper right
  filter(sec < 2000 | sum < 40)

models <- as.tibble(1:n) %>%
  add_column(start = 0, c = 0, k = 0, r_sq = 0)

preds <- matrix(0,nrow(all_models),n)

for (i in 1:n) {
  subset <- filter(all_models, sec > i*increment+start-increment)
  temp <- lm(log(sum) ~ sec, data = subset)
  
  models$start[i] <- i*increment+start-increment
  models$c[i] <- tidy(temp)$estimate[1]
  models$k[i] <- tidy(temp)$estimate[2]
  models$r_sq[i] <- glance(temp)$r.squared[1]
  
  for (j in 1:nrow(all_models)) {
    preds[j,i] <- exp(models$c[i]+models$k[i]*all_models$sec[j])
  }
}

models

all_models <- cbind(all_models, preds)

colnames(all_models)[3:(nrow(models)+2)]<-paste0("V",seq(start,start+(n-1)*increment,increment))

all_models %>%
  filter(sec > 1650) %>%
  ggplot(aes(sec)) +
  geom_point(aes(y = log(sum)), alpha = .2) +
  geom_line(aes(y = log(V1650)), col = "purple") +
  geom_line(aes(y = log(V1850)), col = "green")

```

